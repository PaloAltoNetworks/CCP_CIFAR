[Critical]
train_fp: string;                                   Full path to the encoded training data NPZ file.
val_fp: string;                                     Full path to the encoded validation data NPZ file.
y_mask_fp: string;                                  Full path to the encoded Y mask NPZ file.
save_dir: string;                                   Full path the directory in which all results will be stored.
z_dims: int,int,...;                                Number of neurons in the contrastive projection head. The last dimesion is the size of vectors which have similarities computed upon them.
g_dims: int,int,...;                                Number of neurons in the classification projection head (the final projection to class scores will be added automatically).
sim_metric: [siamese/adj_cos/angular/sqrt_cos];     Which similarity function to use.
drop_keep_prob: float;                              Probability of a neuron NOT shutting off in dropout layer.
contrastive_batch_size: int;                        Batch size for any contrastive loss.
cls_min_epochs: int;                                Minimum number of epochs that must be processed before termination during classifier training.
cls_batch_size: int;                                Batch size for any classification loss.
cls_epochs_per_eval: int;                           The number of epochs processed until an evaluation during classifier training (set to 0 to prevent classifier training).
cls_max_evals_since_overwrite: int;                 The maximum number of evaluations without improvement until training is terminated during classifier training (set to 0 to prevent classifier training).
do_warmup: bool;                                    Whether to use self-supervised pretraining for warmup.
activation: [relu/gelu/elu];                        Choice of activation function.
tau: float;                                         Temperature parameter used inside the contrastive loss.
sc_ema_weight: int;                                 The EMA weight to accumulate the soft contrastive loss over batches.
sc_max_epochs_since_overwrite: int;                 Defines the termination condition for a CCP iteration. How many epochs to process without an improvement in the EMA of soft contrastive loss until termination.
wu_max_epochs_since_overwrite: int;                 Defines the termination condition for warmup. How many epochs to process without an improvement in the EMA of soft contrastive loss (fully unsupervised) until termination.
ccp_iter_schedule: int,int,...;                     Comma separated list indicating the amount of epochs per CCP iteration. Use -1 to run until loss convergence. Leave empty if you want to skip CCP.
alter_first_iter: bool;                             Alter the first CCP iteration to use a low learning rate.

[Optional]
l2_lambda: float;                                   Coefficient for L2 regularization (defaults to 0.0).
learning_rate: float;                               Learning rate for the loss function (defaults to 0.06).
random_seed: int;                                   Random seed for repeatable randomness (defaults to utils.random_seed()).
eval_on_train_data: bool;                           Whether to also measure train set performance every time you measure validation performance (defaults to True).
record_batch_evals: bool;                           Whether or not to record batch performance in a CSV summary file (defaults to True).
trans_in_ccp: bool;                                 Whether to use transformations during CCP iterations (defaults to True).
trans_in_cls: bool;                                 Whether to use transformations during classifier training (defaults to True).
scale_q: bool;                                      Whether to perform scaling of Q vectors (defaults to True).
init_q_fp: string;                                  Full path to the NPZ file containing pre-determined Q vectors you want to use either in classifier training or more iterations of CCP.
max_kl_div: float;                                  The maximum KL-Divergence acceptable. Used for choosing what percentage of weakest Q vectors to reset during subsampling (or after loading Q vectors; defaults to 0.0).
noise_ratio: float;                                 What percent in decimal (use 0.5 for 50%) of known labels do you want to perturb with noise (applied to each class; defaults to 0.0).
cifar_version: int;                                 Either 10 for CIFAR-10 or 100 for CIFAR-100 (defaults to 10).
warmup_chk_path: str;                               Path to the checkpoint file for an already warmed-up network.
use_cred: bool;                                     Whether to use credibility (for ablation analysis; defaults to True).
use_comb_loss: bool;                                Combine the contrastive and cross entropy losses during classifier building (defaults to True).
